{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading page http://xkcd.com...\n",
      "Downloading image http://imgs.xkcd.com/comics/adjusting_a_chair.png...\n",
      "Downloading page http://xkcd.com/2143/...\n",
      "Downloading image http://imgs.xkcd.com/comics/disk_usage.png...\n",
      "Downloading page http://xkcd.com/2142/...\n",
      "Downloading image http://imgs.xkcd.com/comics/dangerous_fields.png...\n",
      "Downloading page http://xkcd.com/2141/...\n",
      "Downloading image http://imgs.xkcd.com/comics/ui_vs_ux.png...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "#! python3\n",
    "# downloadXkcd.py - Downloads every single XKCD comic.\n",
    "\n",
    "import requests, os, bs4\n",
    "\n",
    "headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3626.119 Safari/537.36',\n",
    "    }\n",
    "\n",
    "url = 'http://xkcd.com'              # starting url\n",
    "os.makedirs('xkcd', exist_ok=True)   # store comics in ./xkcd\n",
    "i = 1\n",
    "while not url.endswith('#') and i<=4:\n",
    "    # TODO: Download the page.\n",
    "    print('Downloading page %s...' % url)\n",
    "    res = requests.get(url, headers=headers)\n",
    "    res.raise_for_status()\n",
    "\n",
    "    soup = bs4.BeautifulSoup(res.text, 'html.parser')\n",
    "\n",
    "    # TODO: Find the URL of the comic image.\n",
    "    comicElem = soup.select('#comic img')\n",
    "    if comicElem == []:\n",
    "         print('Could not find comic image.')\n",
    "    else:\n",
    "         try:\n",
    "            comicUrl = 'http:' + comicElem[0].get('src')\n",
    "            # Download the image.\n",
    "            print('Downloading image %s...' % (comicUrl))\n",
    "            res = requests.get(comicUrl)\n",
    "            res.raise_for_status()\n",
    "        \n",
    "        except requests.exceptions.MissingSchema:\n",
    "            # skip this comic\n",
    "            prevLink = soup.select('a[rel=\"prev\"]')[0]\n",
    "            url = 'http://xkcd.com' + prevLink.get('href')\n",
    "            continue\n",
    "\n",
    "    # Save the image to ./xkcd.\n",
    "    fileName = str(int(soup.select('a[rel=\"prev\"]')[0].get('href').strip('/'))+1) +'-'+os.path.basename(comicUrl)\n",
    "    imageFile = open(os.path.join('xkcd', fileName), 'wb')\n",
    "    for chunk in res.iter_content(100000):\n",
    "        imageFile.write(chunk)\n",
    "    imageFile.close()\n",
    "\n",
    "    #create an html file with images and title\n",
    "    comicTitle = comicElem[0].get('title')\n",
    "    html = '<img src=\"'+fileName+'\"><br /><b>'+fileName+'</b>- '+comicTitle+'<hr />'\n",
    "    titleFile = open(os.path.join('xkcd', 'xkcdTitles.html'),'a') \n",
    "    titleFile.write(html+'\\n')\n",
    "    titleFile.close()\n",
    "\n",
    "    # Get the Prev button's url.\n",
    "    prevLink = soup.select('a[rel=\"prev\"]')[0]\n",
    "    url = 'http://xkcd.com' + prevLink.get('href')\n",
    "    i+=1\n",
    "\n",
    "print('Done.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
